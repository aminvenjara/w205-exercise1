# w205-exercise1

I found IPythonNotebook a much easier way to engage with Spark and Hive. It took some setup to get this working, especially to be able to control an AWS instance,  but I found it much easier than the command prompt and a better way to preserve and test code. I followed the instructions here to get the setup working:  http://blog.impiyush.me/2015/02/running-ipython-notebook-server-on-aws.html. 

All elements of my homework are included in the Homework1_Amin_Venjara.ipynb notebook, except for the initial data loading (which is in the load_data_lake.sh script. The construction of tables, loading of data, ERD diagram, transformation, analysis, results queries and explanation are all included in the IPython Notebook to enable easier reading and navigation. 

Note: I have also created a hive_base_ddl.sql file based on some initial work and to practice with DDL statements, but chose to work with the tables created here as the basis for my analysis and queries.
